{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, subprocess\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/library/Documents/ML_project/basenji_genomics_ai/experiments/reproduction/notebooks\n",
      "Changed working directory to: /Users/library/Documents/ML_project/basenji_genomics_ai/experiments/reproduction\n"
     ]
    }
   ],
   "source": [
    "# get working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "# change to parent directory\n",
    "os.chdir(\"..\")\n",
    "print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, you first need to convert your sequences and targets into the input HDF5 format. Check out my tutorials for how to do that; they're linked from the [main page](../README.md).\n",
    "\n",
    "For this tutorial, grab a small example HDF5 that I constructed here with 10% of the training sequences and only GM12878 targets for various DNase-seq, ChIP-seq, and CAGE experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(glob.glob('data/heart_l131k/tfrecords/*.tfr')) == 0:\n",
    "    subprocess.call('curl -o data/heart_l131k.tgz https://storage.googleapis.com/basenji_tutorial_data/heart_l131k.tgz', shell=True)\n",
    "    subprocess.call('tar -xzvf data/heart_l131k.tgz', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to decide what sort of architecture to use. This grammar probably needs work; my goal was to enable hyperparameter searches to write the parameters to file so that I could run parallel training jobs to explore the hyperparameter space. I included an example set of parameters that will work well with this data in models/params_small.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run [basenji_train.py](https://github.com/calico/basenji/blob/master/bin/basenji_train.py) to train a model. The program will offer training feedback via stdout and write the model output files to the prefix given by the *-s* parameter.\n",
    "\n",
    "The most relevant options here are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| -o | models/heart | Directory to save training logs and model checkpoints. |\n",
    "| params_file | models/params_small.json | JSON specified parameters to setup the model architecture and optimization. |\n",
    "| data_dir | data/heart_l131k | Data directory containing the test input and output datasets as generated by [basenji_data.py](https://github.com/calico/basenji/blob/master/bin/basenji_data.py) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run training\n",
    "# it takes too long\n",
    "# best model was downloaded below\n",
    "! python basenji_train.py -o models/heart models/params_small.json data/heart_l131k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find what's using port 8080\n",
    "lsof -ti:8080\n",
    "\n",
    "# Kill the process\n",
    "kill -9 $(lsof -ti:8080)\n",
    "\n",
    "# Then try starting MLflow again\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train, uncomment the following line and run it. Depending on your hardware, it may require several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can just download a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1157k  100 1157k    0     0   442k      0  0:00:02  0:00:02 --:--:--  444k\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('models/heart'):\n",
    "    os.makedirs('models/heart')\n",
    "if not os.path.isfile('models/heart/model_best.h5'):\n",
    "    subprocess.call('curl -o models/heart/model_best.h5 https://storage.googleapis.com/basenji_tutorial_data/model_best.h5', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models/heart/model_best.tf will now specify the name of your saved model to be provided to other programs.\n",
    "\n",
    "To further benchmark the accuracy (e.g. computing significant \"peak\" accuracy), use [basenji_test.py](https://github.com/calico/basenji/blob/master/bin/basenji_test.py).\n",
    "\n",
    "The most relevant options here are:\n",
    "\n",
    "| Option/Argument | Value | Note |\n",
    "|:---|:---|:---|\n",
    "| --ai | 0,1,2 | Make accuracy scatter plots for targets 0, 1, and 2. |\n",
    "| -o | output/heart_test | Output directory. |\n",
    "| --rc | | Average the forward and reverse complement to form an ensemble predictor. |\n",
    "| --shifts | | Average sequence shifts to form an ensemble predictor. |\n",
    "| params_file | models/params_small.json | JSON specified parameters to setup the model architecture and optimization. |\n",
    "| model_file | models/heart/model_best.h5 | Trained saved model parameters. |\n",
    "| data_dir | data/heart_l131k | Data directory containing the test input and output datasets as generated by [basenji_data.py](https://github.com/calico/basenji/blob/master/bin/basenji_data.py) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-29 06:53:47.104635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " sequence (InputLayer)       [(None, 131072, 4)]          0         []                            \n",
      "                                                                                                  \n",
      " stochastic_reverse_complem  ((None, 131072, 4),          0         ['sequence[0][0]']            \n",
      " ent (StochasticReverseComp   ())                                                                 \n",
      " lement)                                                                                          \n",
      "                                                                                                  \n",
      " stochastic_shift (Stochast  (None, 131072, 4)            0         ['stochastic_reverse_complemen\n",
      " icShift)                                                           t[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.nn.gelu (TFOpLambda)     (None, 131072, 4)            0         ['stochastic_shift[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 131072, 64)           3840      ['tf.nn.gelu[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 131072, 64)           256       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 16384, 64)            0         ['batch_normalization[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " tf.nn.gelu_1 (TFOpLambda)   (None, 16384, 64)            0         ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 16384, 64)            20480     ['tf.nn.gelu_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 16384, 64)            256       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 4096, 64)             0         ['batch_normalization_1[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " tf.nn.gelu_2 (TFOpLambda)   (None, 4096, 64)             0         ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 4096, 72)             23040     ['tf.nn.gelu_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 4096, 72)             288       ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 1024, 72)             0         ['batch_normalization_2[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " tf.nn.gelu_3 (TFOpLambda)   (None, 1024, 72)             0         ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 1024, 32)             6912      ['tf.nn.gelu_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 1024, 32)             128       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.gelu_4 (TFOpLambda)   (None, 1024, 32)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 1024, 72)             2304      ['tf.nn.gelu_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 1024, 72)             288       ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024, 72)             0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1024, 72)             0         ['max_pooling1d_2[0][0]',     \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " tf.nn.gelu_5 (TFOpLambda)   (None, 1024, 72)             0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 1024, 32)             6912      ['tf.nn.gelu_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 1024, 32)             128       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.gelu_6 (TFOpLambda)   (None, 1024, 32)             0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 1024, 72)             2304      ['tf.nn.gelu_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 1024, 72)             288       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 1024, 72)             0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 1024, 72)             0         ['add[0][0]',                 \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.gelu_7 (TFOpLambda)   (None, 1024, 72)             0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 1024, 32)             6912      ['tf.nn.gelu_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 1024, 32)             128       ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.gelu_8 (TFOpLambda)   (None, 1024, 32)             0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 1024, 72)             2304      ['tf.nn.gelu_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 1024, 72)             288       ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 1024, 72)             0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 1024, 72)             0         ['add_1[0][0]',               \n",
      "                                                                     'dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.gelu_9 (TFOpLambda)   (None, 1024, 72)             0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 1024, 32)             6912      ['tf.nn.gelu_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 1024, 32)             128       ['conv1d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.gelu_10 (TFOpLambda)  (None, 1024, 32)             0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 1024, 72)             2304      ['tf.nn.gelu_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 1024, 72)             288       ['conv1d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 1024, 72)             0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 1024, 72)             0         ['add_2[0][0]',               \n",
      "                                                                     'dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.gelu_11 (TFOpLambda)  (None, 1024, 72)             0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 1024, 32)             6912      ['tf.nn.gelu_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 1024, 32)             128       ['conv1d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.gelu_12 (TFOpLambda)  (None, 1024, 32)             0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 1024, 72)             2304      ['tf.nn.gelu_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 1024, 72)             288       ['conv1d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 1024, 72)             0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 1024, 72)             0         ['add_3[0][0]',               \n",
      "                                                                     'dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.gelu_13 (TFOpLambda)  (None, 1024, 72)             0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 1024, 32)             6912      ['tf.nn.gelu_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 1024, 32)             128       ['conv1d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.gelu_14 (TFOpLambda)  (None, 1024, 32)             0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 1024, 72)             2304      ['tf.nn.gelu_14[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 1024, 72)             288       ['conv1d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 1024, 72)             0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 1024, 72)             0         ['add_4[0][0]',               \n",
      "                                                                     'dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.gelu_15 (TFOpLambda)  (None, 1024, 72)             0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 1024, 64)             4608      ['tf.nn.gelu_15[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 1024, 64)             256       ['conv1d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 1024, 64)             0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.nn.gelu_16 (TFOpLambda)  (None, 1024, 64)             0         ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024, 3)              195       ['tf.nn.gelu_16[0][0]']       \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReve  (None, 1024, 3)              0         ['dense[0][0]',               \n",
      " rse)                                                                'stochastic_reverse_complemen\n",
      "                                                                    t[0][1]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111011 (433.64 KB)\n",
      "Trainable params: 109235 (426.70 KB)\n",
      "Non-trainable params: 1776 (6.94 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model_strides [128]\n",
      "target_lengths [1024]\n",
      "target_crops [0]\n",
      "45/45 [==============================] - 83s 2s/step - loss: 0.3243 - pearsonr: 0.5543 - r2: 0.2619\n",
      "\n",
      "Test Loss:         0.32431\n",
      "Test PearsonR:     0.55433\n",
      "Test R2:           0.26188\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "! python basenji_test.py --ai 0,1,2 -o output/heart_test --rc --shifts \"1,0,-1\" models/params_small.json models/heart/model_best.h5 data/heart_l131k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/09/29 11:28:47 INFO mlflow.tracking.fluent: Experiment with name 'basenji_genomics' does not exist. Creating a new experiment.\n",
      "Running basenji_test.py...\n",
      "Logged metrics from output/heart_test/acc.txt\n",
      "Testing completed! Run ID: 9cbf68286aa54dedb173d006c1cadc86\n",
      "Test results logged to MLflow\n",
      "Artifacts: output/heart_test\n",
      "2025/09/29 11:29:03 INFO mlflow.tracking._tracking_service.client: üèÉ View run basenji_heart_testing at: http://127.0.0.1:8080/#/experiments/567337574845174630/runs/9cbf68286aa54dedb173d006c1cadc86.\n",
      "2025/09/29 11:29:03 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/567337574845174630.\n"
     ]
    }
   ],
   "source": [
    "# test with mlflow tracking\n",
    "! python mlflow_test_tracking.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view mlflow results\n",
    "http://127.0.0.1:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*data/heart_test/acc.txt* is a table specifiying the Pearson correlation and R2 for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\tpearsonr\tr2\tidentifier\tdescription\n",
      "0\t0.51173\t0.19405\tCNhs11760\taorta\n",
      "1\t0.64497\t0.39054\tCNhs12843\tartery\n",
      "2\t0.50629\t0.20107\tCNhs12856\tpulmonic_valve\n"
     ]
    }
   ],
   "source": [
    "! cat output/heart_test/acc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directories *pr*, *roc*, *violin*, and *scatter* in *data/heart_test* contain plots for the targets indexed by 0, 1, and 2 as specified by the --ai option above.\n",
    "\n",
    "E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('output/heart_test/pr/t0.pdf', width=600, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenji_genomics_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
